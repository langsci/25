%% -*- coding:utf-8 -*-

\chapter*{Preface for Part II}

\largerpage
This book is very long. For technical reasons it was split into two parts in the print version of
earlier editions. As of 2020 the book can be published as one volume, but there are still the two
parts and I think it is helpful for the readers to keep this preface for Part II.

The first part contains the introduction to all the theories and the second part is a collection of
topics that are relevant for more than one theory, so it would be inappropriate to discuss them
within one of the chapters of Part I. While Part~I has a more introductory character and can be used
for teaching BA and MA students, the material in Part~II is for more advanced readers. I never used
it for teaching; it may be a good resource for classes on these topics nevertheless. In what follows, I
give a brief overview of the chapters of Part~II.

Chapter~\ref{chap-innateness} concerns the assumption of
innate domain-specific knowledge, some sort of Universal Grammar. This is probably the hottest
debate in linguistics and the side one takes in this debate has severe consequences for the theories
that one considers acceptable. In Mainstream Generative Grammar (MGG), lots of invisible elements are
postulated and in some versions of MGG, it is claimed that these are present in the grammars of all languages of the
world, even though there is no direct evidence for these categories in some of the languages. Usually the motivation for
assuming an empty element is that there is another language with visible material in the respective
position. Whether one considers such an argumentation as legitimate crucially depends on whether one
believes in innate domain-specific knowledge. Chapter~\ref{chap-innateness} tries to summarize the
discussion and to show that for all claims regarding the existence of Universal Grammar there are
counterclaims. \citet*{HCF2002a} greatly revised Chomsky's assumptions regarding UG. According to them,
UG contains rather few and abstract constraints, but nevertheless UG lives on in the theories
developed today and in the way arguments for them are made. Hence, a chapter like
Chapter~\ref{chap-innateness} is important to understand the discussions and the alternatives to the
theories developed in MGG.

Chapter~\ref{chap-mts} deals with the difference of generative"=enumerative and model-theoretic
approaches. Generative-enumerative approaches (basically phrase-structure grammars and MGG variants
of it) enumerate a set of strings considered to be well-formed with respect to a grammar and
possibly a set of transformations. The model-theoretic view does not say anything about sets but
rather deals with formulating well-formedness conditions for utterances. While this seems to be very
similar at first glance, there are interesting differences in various
respects. Chapter~\ref{chap-mts} deals with utterance fragments and graded acceptability and
discusses alleged problems for model-theoretic approaches. 

Chapter~\ref{chap-competence-performance} introduces the competence/performance distinction. Some researchers
reject this distinction completely (most of the researchers working within CxG), others assume it
and try to develop models that are performance"=compatible (HPSG, LFG, CG, TAG) and others develop
models that are highly implausible from a performance point of view (lots of Minimalist
work). Chapter~\ref{chap-competence-performance} introduces the concepts, discusses whether it makes sense to
distinguish competence and performance (I think it does) and examines what is required for
performance-compatible competence models.

It is often argued that theory X must be wrong since it does not explain how language can be
acquired. Interestingly, these accusations go both ways: Construction Grammarians criticize
Minimalists for assuming half of their theory to be hard coded in our genetic material and
Minimalists claim that constructionist theories do not have an explanation for there being recursive
structures. Chapter~\ref{chap-acquisition} discusses the major approaches to acquisition and explains
where they differ and what shortcomings exist.

Chapter~\ref{chap-complexity} deals with the generative capacity of grammar formalisms. The
generative capacity played an important role in the history of generative grammar. Early versions
turned out to be too powerful, resulting in quite radical changes of the framework in the 1970s and
1980s. One key advantage of GPSG was that it was much more restrictive than the transformational
approaches that were around at the time. As it turned out, it was too restrictive to model language
as such since there were languages that could be shown to require more powerful machinery. This lead
to the development of HPSG. The HPSG formalism has Turing power, which is the worst complexity a formalism can
have. Somewhat ironically, most proponents of HPSG do not care about this at
all. Chapter~\ref{chap-complexity} explains why.

\addlines
Chapter~\ref{chap-blr} is a brief chapter including the discussion of three topics that come up
again and again: binary branching vs.\ flat structures, locality and recursion. Some researchers
argue (without proof) that all theories should assume binary branching structures because otherwise
the grammars are not acquirable, while others argue for the opposite view, again often with acquisition
arguments (Section~\ref{sec-branching}). Locality is an issue that is important both in Minimalism and in other theories like HPSG
and LFG. However, there are differences in what is understood by
locality. Section~\ref{sec-locality} deals with these issues. Languages usually have recursive
structures. So frameworks have to have ways to account for this. All the frameworks discussed in
this book do account for recursion despite claims to the contrary. This is topic of
Section~\ref{sec-recursion}.

Chapter~\ref{chap-empty} deals with empty elements. While some theories have more invisible units
in their trees than visible ones (see Figure~\ref{Abbildung-Radfords-PP} on
page~\pageref{Abbildung-Radfords-PP}), there are frameworks that do not assume any empty elements,
referring to acquisition again. The chapter shows that certain grammars with empty elements can be
converted into grammars without empty elements. I show that empty elements are not required for
semantic reasons; underspecification can be used instead. The chapter shows how important the assumptions
about UG (Chapter~\ref{chap-innateness}) are: if empty elements correspond to visible material that
in certain situations occupies the place of the empty element, then there are chances for them to be
acquired from data. If the empty elements are stipulated with reference to material in other
languages, there is a real acquisition problem. A final section shows that (some) empty elements can
be replaced by lexical rules (or templates), which correspond to a certain type of
transformation. This relativizes the debate that arose around stipulating such theoretical entities.
 
When it comes to mechanisms that are used in different frameworks, there is a further difference
between (some variants of) GB/Minimalism and the other theories. Some theories in the
transformational frameworks assume that extraction, scrambling and passive are dealt with using the
same descriptive tool: movement. Other theories use lexical rules, different phrasal schemata and
\slasch propagation techniques. Chapter~\ref{chap-scrambling-extraction-passive} shows that
phenomena like the so"=called remote passive that seem to require movement can be dealt with without
movement. The chapter repeats an example from the GB chapter that showed that the movement"=based
analysis of the German passive is problematic, since nothing moves in German sentences. Passive is a
phenomenon that is independent of movement; it is just English that is SVO and requires a subject
before the verb. Since German does not require subjects, nothing has to be reordered. Dependency
Grammar proposals assuming the same descriptive tool for the three phenomena are discussed as well,
their shortcomings are pointed out and it is concluded that the three phenomena are independent
or at least have to be distinguishable in terms of their treatment in a theory.

Chapter~\ref{chap-phrasal} discusses a further highly controversial issue: the question of whether
language consists of phrasal patterns or whether there are abstract combinatorial rules that combine
lexical items that contain rich information. Again, questions of language acquisition play a role
here. This chapter is rather long but it reflects the complexity of the discussion in the
literature. Many arguments for and against phrasal constructions are evaluated and it is shown that
grammars have to be able to account for phrasal patterns, but that so"=called argument structure
constructions are better treated lexically. This discussion connects nicely to the GPSG--HPSG
transition in the 1980s where researchers switched from a phrasal model to a lexical one in the
spirit of Categorial Grammar.

The brief Chapter~\ref{chap-potenital-structure} is related to the topic of
Chapter~\ref{chap-phrasal} but it compares the TAG, LFG and HPSG approaches to complex predicates
and points out that there are problems with a certain treatment of complex predicates in TAG. TAG is
very similar in spirit to phrasal Construction Grammar approaches: the elementary trees of TAG are
phrasal patterns. It is shown that lexical models like HPSG have an advantage over the phrasal TAG approach
since they specify lexical potential of items, which is not necessarily the same as actual
realization of dependents. It is pointed out that the LFG analysis of complex predicates allowing
for overrides of lexical information at phrasal nodes lies somewhere in the middle between TAG and HPSG.

Chapter~\ref{Abschnitt-UG-mit-Hierarchie} showcases a way to develop linguistic theories that capture
cross"=linguistic generalizations. It differs from the general top"=down approach in Minimalism,
where it is assumed that certain constraints hold for all languages. Instead, constraints that hold
for known languages are collected in sets in a bottom-up way. The most general set contains all
constraints that hold for all known languages. This approach is independent of the assumption of an
innate UG and hence compatible with both CxG and Minimalism. The chapter also contains some
speculations on how to integrate universal constraints in an Cinque"=like UG way in case there turns
out to be an empirical basis for this.

Chapter~\ref{chap-conclusion} draws some conclusions as to what an appropriate framework for
describing languages should look like.

  




%      <!-- Local IspellDict: en_US-w_accents -->
