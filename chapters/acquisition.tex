%% -*- coding:utf-8 -*-
\chapter{Language acquisition}
\label{chap-acquisition}

Linguists\is{acquisition|(} and philosophers are fascinated by the human ability to acquire language. Assuming the relevant input during childhood,
language acquisition normally takes place completely effortlessly.
\citet[\page  24--25]{Chomsky65a} put forward the requirement that a grammatical theory must provide a plausible model of language acquisition.
Only then could it actually explain anything and would otherwise remain descriptive at best. In this section, we will discuss
theories of acquisition from a number of theoretical standpoints.


\section{Principles \& Parameters}
\label{Abschnitt-PP}\label{sec-pro-drop}

A\is{parameter|(}\is{Principles \& Parameters|(} very influential explanation of language acquisition is Chomsky's Principles \& Parameters model
\citeyearpar{Chomsky81a}. Chomsky assumes that there is an innate Universal Grammar that contains knowledge that is equally relevant for all languages.
Languages can then vary in particular ways. For every difference between languages in the area of core grammar\is{core grammar}, there is a feature with a specific
value. Normally, the value of a parameter is binary, that is, the value is either `+' or `$-$'.
Depending on the setting of a parameter, a language will have certain properties, that is, setting a parameter determines whether
a language belongs to a particular class of languages.
Parameters are assumed to influence multiple properties of a grammar simultaneously
\citep[\page 6]{Chomsky81a}.
% auch [\page 131, 133]{PL2013a}. 
For example, \citet{Rizzi86a} claims that the pro"=drop parameter\is{parameter!pro"=drop} affects
whether referential subjects can be omitted, the absence of expletives, subject 
extraction\is{extraction!subject} from clauses with complementizers (\emph{that}-t contexts\is{that-t}) and interrogatives and
finally the possibility of realizing the subject postverbally in VO"=languages (see
\citealp[Section~4.3]{Chomsky81a}; \citealp[\page 12]{Meisel95a}). It has been noted that there are counter"=examples to all the correlations assumed.\footnote{%
\label{fn-Expletiva-Pro-Drop}%
  See \citew{Haider94c-u} and \citew[Section~2.2]{Haider2001a} for an overview. Haider assumes that there is at least a correlation
  between the absence of expletive subjects and pro"=drop. However, Galician\il{Galician} is a pro"=drop language with expletive subject
  pronouns \citep[Section~2.5]{RU90a-u}. \citet[\page 314]{Franks95a-u} cites Upper\il{Sorbian!Upper} and Lower Sorbian\il{Sorbian!Lower} as pro"=drop
  languages with expletive subjects. \citet[\page 218]{SP2002b} point out that there is an expletive pronoun \emph{ci} in modern Italian\il{Italian}
  although Italian\il{Italian} is classed as a pro"=drop language.}
Another example of a parameter is the Head Directionality Parameter discussed in Section~\ref{Abschnitt-Kopfstellungsparameter}.
As was shown, there are languages where heads govern in different directions. In his overview article, \citet{Haider2001a} still mentions
the parametrized Subjacency Principle\is{parameter!subjacency} but notes that subjacency\is{subjacency} is no longer assumed as a principle
in newer versions of the theory (see Section~\ref{Abschnitt-Subjazenz-Extraktion} for more on subjacency).

\citet{Snyder2001a} discovered a correlation of various phenomena with productive root compounding
as it is manifested for instance in compounding of two nouns. He argues that the acquisition of
complex predicate formation is connected to the acquisition of compound structures and that there is
a parameter that is responsible for this type of compounding and simultaneously for the following set of
phenomena:
\eal\settowidth\jamwidth{(double-object dative)}
\ex John painted the house red.                 \jambox{(resultative\is{resultative construction})}
\ex Mary picked the book up/picked up the book. \jambox{(verb-particle\is{verb!particle})}
\ex Fred made Jeff leave.                       \jambox{(\emph{make}-causative)}
\ex Fred saw Jeff leave.                        \jambox{(perceptual report)}
\ex Bob put the book on the table.              \jambox{(\emph{put}-locative)}
\ex Alice sent the letter to Sue.               \jambox{(\emph{to}-dative)}
\ex Alice sent Sue the letter.                  \jambox{(double-object dative\is{verb!ditransitive})}
\zl 
Snyder examined languages from various language groups: Afroasiatic, Austroasiatic, Austronesian,
Finno-Ugric, Indo-European (Germanic, Romance, Slavic), Japanese"=Korean, Niger"=Kordofanian (Bantu),
and Sino"=Tibetan, as well as American Sign\il{sign language!American (ASL)} Language and the language isolate Basque\il{Basque}. The languages
that were examined either had all of these phenomena or none. This was tested with native speakers
of the respective languages. In addition the claim that these phenomena are acquired once noun-noun
compounds are used productively was tested for English using CHILDES data. The result was positive
with the exception of the double object construction, for which an explanation was provided. The
correlation of the phenomena in (\mex{0}) is interesting and was interpreted as proof of the
existence of a parameter that correlates several phenomena in a language. However, \citet{Son2007a}
and \citet{SonS2008a} showed that Snyder's claims for Japanese\il{Japanese} were wrong and that there
are further languages like Korean\il{Korean}, Hebrew\il{Hebrew}, Czech\il{Czech},
Malayalam\il{Malayalam}, Javanese\il{Javanese}  in which some of the phenomena show no correlations. 
%% \citet[\page 395]{SonS2008a} conclude that language"=wide parameters of the type
%% discussed here do never partition the world languages into two sets and that all parameters that
%% were suggested in the past had to be subdivided into smaller ones. They therefore suggest that parametric variation
%% is confined to lexical items.

\largerpage[2]
\citet{GW94a} discuss the acquisition of constituent order and assume three parameters that concern the
position of the verb relative to the subject (SV vs.\ VS)\is{parameter!SV} and relative to the
object (VO vs.\ OV)\is{parameter!V2} as well as the V2"=property\is{parameter!V2}. There is no consensus in the literature about which
parameters determine the make-up of languages (see \citealp[Section~3.2]{Newmeyer2005a} and \citealp{Haspelmath2008a}
for an overview and critical discussion).
\citet[\page 346--347]{Fodor98a} assumes that there are 20 to 30 parameters, \citet[\page 408]{GW94a}
mention the number 40, \citet[\page 349]{Baker2003b} talks of 10 to 20 and \citet[\page 541]{RH2005a}
of 50 to 100. There is no consensus in the literature as to which parameters one should assume, how they interact
and what they predict. However, it is nevertheless possible to contemplate how a grammar of an individual language
could be derived from a UG with parameters that need to be set.
Chomsky's original idea \citeyearpar[Section~3.5.1]{Chomsky86a} was that the child sets the value of
a parameter based on the language input as soon as the relevant evidence is present from the input
(see also \citealp*{GW94a,NKN2001a}). At a given point in time, the learner has a grammar with certain parameter
 settings that correspond to the input seen so far. In order to fully acquire a grammar, all parameters must be assigned a value. In theory,
 thirty utterances should be enough to acquire a grammar with thirty parameters if these utterances
 provide unambiguous evidence for a particular parameter value.

This approach has often been criticized. If setting a parameter leads to a learner using a
different grammar, one would expect sudden changes in linguistic behavior. This is, however,
not the case (\citealp[\page 731]{Bloom93a}). \citet[\page 343--344]{Fodor98a} also notes
the following three problems: 1) Parameters can affect things that are not visible from the
perceptible constituent order. 2) Many sentences are ambiguous with regard to the setting of a particular
parameter, that is, there are sometimes multiple combinations of parameters compatible with one
utterance. Therefore, the respective utterances cannot be used to set any parameters \citep{BN96a,Fodor98b}. 3) There is a problem with the interaction of parameters.
Normally multiple parameters play a role in an utterance such that it can be difficult to determine
which parameter contributes what and thus how the values should be determined.\nocite{Pullum83a}

Points 1) and 2) can be explained using the constituent order parameters of Gibson \& Wexler:\il{English}
imagine a child hears sentences such as the English and the German examples in (\mex{1}):
\eal
\ex Daddy drinks juice.
\ex 
\gll Papa trinkt Saft.\\
     daddy drinks juice\\
\zl
These sentences look exactly the same, even though radically different structures are assumed for each.
According to the theories under discussion, the English sentence has the structure shown in Figure~\ref{Abb-GB-englischer-Satz-ohne-Hilfsverb} on
page~\pageref{Abb-GB-englischer-Satz-ohne-Hilfsverb} given in abbreviated form in (\mex{1}a).
The German sentence, on the other hand, has the structure in Figure~\ref{Abb-GB-Vorfeldbesetzung} 
on page~\pageref{Abb-GB-Vorfeldbesetzung} corresponding to (\mex{1}b):
\eal
\ex {}[\sub{IP} [Daddy [\sub{I$'$} \_$_k$ [\sub{VP} drinks$_k$ juice]]].
\ex {}[\sub{CP} Papa$_i$ [\sub{C$'$} trinkt$_k$ [\sub{IP} \_$_i$ [\sub{I$'$} [\sub{VP} Saft \_$_k$] \_$_k$]]]].
\zl
English has the basic constituent order SVO\is{SVO}. The verb forms a constituent with the object (VP) and this
is combined with the subject. The parameter setting must therefore be SV, VO and $-$V2. German,
on the other had, is analyzed as a verb"=final and verb"=second language and the parameter values
would therefore have to be SV, OV and $+$V2. If we consider the sentences in (\mex{-1}), we see that
both sentences do not differ from one another with regard to the order of the verb and its arguments.

\citet{Fodor98a,Fodor98b} concludes from this that one first has to build a structure in order to see
what grammatical class the grammar licensing the structure belongs to since one first needs the structure
in (\mex{0}b) in order to be able to see
that the verb in the partial constituent occurs after its argument in the VP (Saft \_$_k$). The question is now how one achieves
this structure. A UG with 30 parameters corresponds to 2$^{30}$ = 1,073,741,824 fully instantiated grammars.
It is an unrealistic assumption that children try out these grammars successively or simultaneously.

\largerpage[2]
\citet{GW94a} discuss a number of solutions for this problem: parameters have a default value\is{parameter!default value}
and the learner can only change a parameter value if a sentence that could previously not be analyzed
can then be analyzed with the new parameter setting (\emph{Greediness Constraint}\is{Greediness Constraint}).
In this kind of procedure, only one parameter can be changed at a time
(\emph{Single Value Constraint}\is{Single Value Constraint}),
which aims at ruling out great leaps leading to extremely different grammars (see \citealp[\page 612--613]{BN96a}, however).
This reduces the processing demands, however with 40 parameters, the worst case could still be that
one has to test 40 parameter values separately, that is, try to parse a sentence with 40 different
grammars. This processing feat is still unrealistic, which is why \citet[\page 442]{GW94a} additionally
assume that one hypothesis is tested per input sentence.
A further modification of the model is the assumption that certain parameters only begin to play a role
during the maturation\is{maturation} of the child. At a given point in time, there could be only a few accessible parameters
that also need to be set. After setting these parameters, new parameters could become available.

In their article, Gibson \& Wexler show that the interaction between input and parameter setting is in no way trivial.
In their example scenario with three parameters, a situation can arise in which a learner sets a parameter in order to analyze
a new sentence, however setting this parameter leads to the fact that the target grammar cannot be acquired because only one value can
be changed at a time and changes can only be made if more sentences can be analyzed than before. The learner reaches a so"=called
local maximum\is{local maximum} in these problematic cases.\footnote{%
	If one imagines the acquisition process as climbing a hill, then the Greediness Constraint\is{Greediness Constraint} ensures
	that one can only go uphill. It could be the case, however, that one begins to climb the wrong hill and can no longer get back down.}
Gibson \& Wexler then suggest assigning a default value to particular parameters, whereby the default value is the one that will cause the learner
to avoid problematic situations. For the V2 parameter\is{parameter!V2}, they assume `$-$' as the default value\is{parameter!default value}.

\citet{BN96a} show that Gibson \& Wexler calculated the problematic conditions incorrectly and
that, if one shares their assumptions, it is even more frequently possible
to arrive at parameter combinations from which it is not possible to reach the target grammar by changing individual parameter values.
They show that one of the problematic cases not addressed by Gibson \& Wexler is $-$V2 (p.\,609) and that the assumption of a default value
for a parameter does not solve the problem as both `+' and `--' can lead to problematic combinations of parameters.\footnote{%
  \citet{Kohl99a,Kohl2000a} has investigated this acquisition model in a case with twelve parameters. Of the 4096 possible grammars,
  2336 (57\%) are unlearnable if one assumes the best initial values for the parameters.
}
In their article, Berwick and Niyogi show that learners in the example scenario above (with three
parameters) learn the target grammar faster if one abandons the Greediness\is{Greediness Constraint} 
or else the Single Value Constraint\is{Single Value Constraint}.
They suggest a process that simply randomly changes one parameter if a sentence cannot be analyzed (\emph{Random Step}\is{Random Step}, p.\,615--616).
The authors note that this approach does not share the problems with the local maxima \is{local maximum} that Gibson \& Wexler had in their example and that it also reaches its goal faster
than theirs. However, the fact that \emph{Random Step} converges more quickly has to do with the quality of the parameter space (p.\,618).
Since there is no consensus about parameters in the literature, it is not possible to assess how the entire system works.

\citet[\page 453]{Yang2004a} has criticized the classic Principles \& Parameters model since abrupt switching between grammars after setting
a parameter cannot be observed. Instead, he proposes the following learning mechanism:
\ea
For an input sentence, $s$, the child:
(i) with probability P$_i$ selects a grammar G$_i$, (ii) analyzes $s$ with G$_i$, (iii) if successful, reward G$_i$ by increasing P$_i$,
otherwise punish G$_i$ by decreasing P$_i$.
\z
Yang discusses the example of the pro"=drop\is{parameter!pro"=drop|(} and topic drop parameters\is{parameter!topic drop}. In pro"=drop languages (\eg Italian\il{Italian|(}),
it is possible to omit the subject and in topic drop languages (\eg Mandarin Chinese\il{Mandarin Chinese}), it possible to omit both the subject and the object if it is
a topic. Yang compares English-speaking\il{English|(} and Chinese-speaking\il{Mandarin Chinese} children noting that English children omit both subjects and objects
in an early linguistic stage. He claims that the reason for this is that English-speaking children start off using the Chinese grammar.

The pro"=drop parameter is one of the most widely discussed parameters in the context of Principles \& Parameters theory and it will
therefore be discussed in more detail here. It is assumed that speakers of English have to learn that all sentences in English require
a subject, whereas speakers of Italian learn that subjects can be omitted.
One can observe that children learning both English\il{English} and Italian\il{Italian} omit subjects (German children too in fact).
Objects are also omitted notably more often than subjects.
There are two possible explanations for this: a competence"=based\is{competence} one and a performance"=based\is{performance} one.
In competence"=based approaches, it is assumed that children use a grammar that allows them to omit subjects and then only later acquire
the correct grammar (by setting parameters or increasing the rule apparatus). In performance"=based approaches, by contrast, the omission of subjects
is traced back to the fact that children are not yet capable of planning and producing long utterances due to their limited brain capacity.
Since the cognitive demands are greatest at the beginning of an utterance, this leads to subjects beings increasingly left out.
 \citet{Valian91a} investigated these various hypotheses and showed that the frequency with which children learning English and Italian respectively omit subjects
 is not the same. Subjects are omitted more often than objects. She therefore concludes that competence"=based explanations are
 not empirically adequate.\todostefan{hier fehlt irgendwie was bei den Details} The omission of
 subjects should then be viewed more as a performance phenomenon (see also \citealp{Bloom93a}). 
 Another argument for the influence of performance factors is the fact that articles of subjects are
 left out more often than articles of objects (31\% vs.\ 18\%, see \citealp[\page
   440]{Gerken91a}). As Bloom notes, no subject article"=drop parameter has been proposed so
 far\is{parameter!subject article drop}. If we explain this phenomenon as a performance phenomenon, then it is also plausible to assume that
the omittance of complete subjects is due to performance issues.\il{Italian|)}\il{English|)}

\citet{Gerken91a} shows that the metrical properties of utterances also play a role: in experiments where children had to repeat sentences,
they omitted the subject/article of the subject more often  than the object/article of the object. Here, it made a difference whether the intonation pattern
was iambic\is{iambus} (weak-strong) or trochaic\is{trochee} (strong-weak). It can even be observed with individual words that children leave out
weak syllables at the beginning of words more often than at the end of the word. Thus, it is more probable that ``giRAFFE'' is reduced to ``RAFFE'' than
``MONkey'' to ``MON''. Gerken assumes the following for the metrical\is{metrics} structure of utterances:
\begin{enumerate}
\item A metrical foot contains one and only one strong syllable.
\item Create maximally binary left-to-right feet.
\item Metrical structure is independent of syntactic structure.
\end{enumerate}
Subject pronouns in English are sentence"=initial and form a iambic foot with the following strongly emphasized verb as in (\mex{1}a).
Object pronouns, however, can form the weak syllable of a trochaic foot as in (\mex{1}b). 
\eal
\ex she KISSED $+$ the DOG
\ex the DOG $+$ KISSED her
\ex PETE $+$ KISSED the $+$ DOG
\zl
Furthermore, articles in iambic feet as in the object of (\mex{0}a) and the subject of (\mex{0}b) are omitted more often
than in trochaic feet such as with the object of (\mex{0}c).

It follows from this that there are multiple factors that influence the omission of elements and that one cannot simply take the behavior
of children as evidence for switching between two grammars.

Apart from what has been discussed so far, the pro"=drop parameter is of interest for another reason: there is a problem when it comes to setting parameters. The standard explanation is
that learners identify that a subject must occur in all English sentences, which is suggested by the appearance of expletive pronouns\is{pronoun!expletive} in 
the input.

As discussed on page~\pageref{fn-Expletiva-Pro-Drop}, there is no relation between the pro"=drop property and the presence of expletives
in a language. Since the pro"=drop property does not correlate with any of the other putative properties either, only the existence
of subject"=less sentences in the input constitutes decisive evidence for setting a parameter. The problem is that there are grammatical utterances
where there is no visible subject. Examples of this are imperatives such as (\mex{1}), declaratives
with a dropped subject as in (\mex{2}a) and even declarative sentences without an expletive such as the  
example in (\mex{2}b) found by \citet[\page 32]{Valian91a} in the New York Times.
\eal
\label{Beispiel-Imperativ-Englisch}
\ex Give me the teddy bear!
\ex Show me your toy!
\zl
\eal
\ex She'll be a big hit. Sings like a dream.\label{ex-sings-like-a-dream}
\ex Seems like she always has something twin-related perking.
\zl
The following title of a Nirvana\is{Nirvana} song also comes from the same year as Valian's article:
\ea
Smells like Teen Spirit.\\
\z
Teen Spirit refers to a deodorant and \emph{smell} is a verb that, both in German and English, requires a referential subject but can also be used with an expletive \emph{it} as subject.
The usage that Kurt Cobain had in mind cannot be reconstructed\footnote{%
  See \url{http://de.wikipedia.org/wiki/Smells_Like_Teen_Spirit}. 2018-02-20.
}, independent of the intended meaning, however, the subject in (\mex{0}) is missing.
Imperatives do occur in the input children have and are therefore relevant for acquisition.
\citet[\page 33]{Valian91a} says the following about them:
\begin{quote}
What is acceptable in the adult community forms part of the child's input, and
is also part of what children must master. The utterances that I have termed
``acceptable'' are not grammatical in English (since English does not have pro
subjects, and also cannot be characterized as a simple VP). They lack subjects
and therefore violate the extended projection principle\is{Extended Projection Principle (EPP)} \citep{Chomsky81a}, which we are assuming.

   Children are exposed to fully grammatical utterances without subjects, in the
form of imperatives. They are also exposed to acceptable utterances which are
not fully grammatical, such as [(\ref{ex-sings-like-a-dream})], as well as forms like, ``Want lunch now?'' The
American child must grow into an adult who not only knows that overt subjects
are grammatically required, but also knows when subjects can acceptably be
omitted. The child must not only acquire the correct grammar, but also master
the discourse conditions that allow relaxation of the grammar. \citep[\page 33]{Valian91a}
\end{quote}
This passage turns the relations on their head: we cannot conclude from the fact that a particular grammatical
theory is not compatible with certain data, 
that these data should not be described by this theory, instead we should modify the incompatible
grammar or, if this is not possible, we should reject it.
Since utterances with imperatives are entirely regular, there is no reason to categorize them as utterances that
do not follow grammatical rules. The quotation above represents a situation where a learner has to acquire two
grammars: one that corresponds to the innate grammar and a second that partially suppresses the rules of innate grammar
and also adds some additional rules.

The question we can pose at this point is: how does a child distinguish which of the data it hears are relevant for which of the two grammars?
\is{parameter!pro"=drop|)}

\citet[\page 347]{Fodor98a} pursues a different analysis that does not suffer from many of the aforementioned problems.
 Rather than assuming that learners try to find a correct grammar among a billion others, she instead assumes that
 children work with a single grammar that contains all possibilities.
She suggests using parts of trees (\emph{treelets}) rather than parameters. These treelets can also be underspecified and
in extreme cases, a treelet can consist of a single feature \citep[\page 6]{Fodor98b}.
A language learner can deduce whether a language has a given property from the usage of a particular treelet.
As an example, she provides a VP treelet consisting of a verb and a prepositional phrase. 
This treelet must be used for the analysis of the VP occurring in \emph{Look at the
  frog}. Similarly, the analysis of an interrogative clause with a fronted \emph{who} would make use
of a treelet with a \emph{wh}"=NP in the specifier of a complementizer phrase (see Figure~\ref{Abb-GB-Wh} on page~\pageref{Abb-GB-Wh}).
In Fodor's version of \ppt, this treelet would be the parameter that licenses \emph{wh}"=movement in (overt) syntax.
Fodor assumes that there are defaults\is{parameter!default value} that allow a learner to parse a sentence even when no or very few
parameters have been set. This allows one to learn from utterances that one would have not otherwise been able to use since there would have
been multiple possible analyses for them. Assuming a default can lead to misanalyses, however: due to a default value, a second
parameter could be set because an utterance was analyzed with a treelet t$_1$ and t$_3$, for example, but t$_1$ was not suited to the particular
language in question and the utterance should have instead been analyzed with the non"=default treelet t$_2$ and the treelet t$_{17}$.
In this acquisition model, there must therefore be the possibility to correct wrong decisions in the parameter setting process. 
Fodor therefore assumes that there is a frequency"=based degree of activation for parameters (p.\,365): treelets that are often
used in analyses have a high degree of activation, whereas those used less often have a lower degree of activation.
In this way, it is not necessary to assume a particular parameter value while excluding others.

Furthermore, Fodor proposes that parameters should be structured hierarchically, that is, only if a parameter has a particular value
does it then make sense to think about specific other parameter values.

Fodor's analysis is -- as she herself notes \citep[\page 385]{Fodor2001a} -- compatible with theories such as HPSG\indexhpsg and TAG\indextag.
\citet[\page 147]{ps} characterize UG as the conjunction of all universally applicable principles:
\ea
UG = P$_1$ $\wedge$ P$_2$ $\wedge$ \ldots{} $\wedge$ P$_n$
\z
As well as principles that hold universally, there are other principles that are specific to a particular language
or a class of languages. Pollard \& Sag give the example of the constituent ordering principle that only holds for English.
English\il{English} can be characterized as follows if one assumes that P$_{n + 1}$--P$_m$ are language"=specific principles,  
L$_{1}$--L$_p$ a complete list of lexical entries and R$_{1}$--R$_q$ a list of dominance schemata relevant for English.
\ea
English = P$_1$ $\wedge$ P$_2$ $\wedge$ \ldots{} $\wedge$ P$_m$ $\wedge$ (L$_{1}$ $\vee$ \ldots{}
$\vee$ L$_p$ $\vee$ R$_{1}$ $\vee$ \ldots{} $\vee$  R$_q$)
\z
In Pollard \& Sag's conception, only those properties of language that equally hold for all languages are
part of UG. Pollard \& Sag do not count the dominance schemata as part of this. However, one can indeed also describe
UG as follows:
\ea
%UG = P$_1$ $\wedge$ P$_2$ $\wedge$ \ldots{} $\wedge$ P$_n$ $\wedge$ (R$_{en\mbox{-}1}$ $\vee$ \ldots{} $\vee$
%R$_{en\mbox{-}q}$  $\vee$ R$_{de\mbox{-}1}$ $\vee$ \ldots{} $\vee$ R$_{de\mbox{-}r}$ $\vee$ \ldots )
$
\mathrm{UG} = 
  \mathrm{P}_1 
  \wedge 
  \mathrm{P}_2 
  \wedge 
  \ldots 
  \wedge 
  \mathrm{P}_n 
  \wedge
              (\mathrm{R}_{\mathrm{en}\mathdash1} 
              \vee 
              \ldots 
              \vee 
              \mathrm{R}_{\mathrm{en}\mathdash q} 
              \vee  
              \mathrm{R}_{\mathrm{de}\mathdash1} 
              \vee 
              \ldots 
              \vee 
              \mathrm{R}_{\mathrm{de}\mathdash r}
	      \vee 
	      \ldots)
$
\z
\largerpage
P$_1$--P$_n$ are, as before, universally applicable principles and
$\mathrm{R}_{\mathrm{en}\mathdash1}$--$\mathrm{R}_{\mathrm{en}\mathdash q}$ are the
(core) dominance schemata of English and $\mathrm{R}_{\mathrm{de}\mathdash1}$--$\mathrm{R}_{\mathrm{de}\mathdash r}$ are the dominance schemata in
German. The dominance schemata in (\mex{0}) are combined by means of disjunctions, that is, not every disjunct needs to have a realization in a specific language. Principles can make reference
to particular properties of lexical entries and rule out certain phrasal configurations.
If a language only contains heads that are marked for final"=position in the lexicon, then grammatical rules that
require a head in initial position as their daughter can never be combined with these heads or their projections.
Furthermore, theories with a type system are compatible with Fodor's approach to language acquisition because 
constraints can easily be underspecified. As such, constraints in UG do not have to make reference to all properties
of grammatical rules: principles can refer to feature values, the language"=specific values themselves do not have to
already be contained in UG. Similarly, a supertype describing multiple dominance schemata that have
similar but language"=specific instantiations can also be part of UG, however the language"=specific details remain open and are then deduced by the learner
upon parsing (see \citealp[Section~9.2]{AW98a}). The differences in activation assumed by Fodor can be captured
by weighting the constraints: the dominance schemata $\mathrm{R}_{\mathrm{en}\mathdash1}$--$\mathrm{R}_{\mathrm{en}\mathdash q}$ etc.\ are sets of
feature"=value pairs as well as path equations. As explained in Chapter~\ref{Abschnitt-Diskussion-Performanz}, 
weights can be added to such constraints and also to sets of constraints. In Fodor's acquisition model, given a German input, the weights for the rules
of English would be reduced and those for the German rules would be increased. Note that in Pollard
\& Sag's acquisition scenario, there are no triggers\is{trigger} for parameter
setting unlike in Fodor's model.
Furthermore, properties that were previously disjunctively specified as part of UG will now be
acquired directly. Using the treelet t$_{17}$ (or rather a possibly underspecified dominance
schema), it is not the case that the value `+' is set for a parameter P$_5$  but rather the activation
potential of t$_{17}$ is increased such that t$_{17}$ will be prioritized for future
analyses.
\is{parameter|)}\is{Principles \& Parameters|)}


\section{Principles and the lexicon}

A variant of the UG"=driven theory of language acquisition would be to assume that principles are so general that they hold
for all languages and individual languages simply differ with regard to their lexicon.
Principles then refer to properties of combined entities. Parameters therefore migrate from principles into the lexicon
\citep[\page 2]{Chomsky99a}. See \citet{MR2010a} for a study of Romance languages in this model and
\citet[\page 395]{SonS2008a} for an analysis of Snyder's examples that were discussed in the
previous section.

At this point, one can observe an interesting convergence in these approaches: most of the theories discussed here assume a very
general structure for the combination of heads with their arguments. For example, in Categorial Grammar and the Minimalist Program,
these are always binary functor"=argument combinations. The way in which constituents can be ordered in a particular language depends
on the lexical properties of the combined elements.

The question that is being discussed controversially at present is whether the spectrum of lexical properties is determined by UG 
\citep[\page 6--7]{Chomsky2007a} and whether all areas of the language can be described with the same general combinatorial possibilities (see Section~\ref{Abschnitt-Phrasale-Konstruktionen} on phrasal constructions).

In Section~\ref{Abschnitt-PP}, I have shown what theories of acquisition assuming innate language
specific knowledge can look like and also that variants of such acquisition theories are compatible
with all the theories of grammar we have discussed.  During this discussion, one should bear in
 mind the question of whether it makes sense at all to assume that English children
use parts of a Chinese grammar during some stages of their acquisition process (as suggested by
\citealp[\page 453]{Yang2004a}), or whether the relevant phenomena can be explained in different ways.
In the following, I will present some alternative approaches that do not presuppose innate language
specific knowledge, but instead assume that language can simply be acquired from the input. The
following section will deal with pattern"=based approaches and
Section~\ref{Abschnitt-Selektionsbasierter-Spracherwerb} will discuss the lexically"=oriented variant
of input"=based language acquisition.

\section{Pattern"=based approaches}
\label{Abschnitt-musterbasiert}

\largerpage
\mbox{}\citet[\page 7--8]{Chomsky81a} proposed that languages can be divided into a core
area\is{core grammar} and a periphery\is{periphery}. The core contains all regular aspects of
language. The core grammar of a language is seen as an instantiation of UG. Idioms\is{idiom} and
other irregular parts of language are then part of the periphery.  Critics of the Principles \&
Parameters model have pointed out that idiomatic and irregular constructions constitute a relatively
large part of our language and that the distinction, both fluid and somewhat arbitrary, is only
motivated theory"=internally (\citealp[Chapter~7]{Jackendoff97a}; \citealp{Culicover99a-u};
\citealp[\page 5]{GSag2000a-u}; \citealp[\page 48]{Newmeyer2005a}; \citealp[\page 619]{Kuhn2007a}).
For example, it is possible to note that there are interactions between various idioms and syntax
\citep*{NSW94a}.  Most idioms in German with a verbal component allow the verb to be moved to
initial position (\mex{1}b), some allow that parts of idioms can be fronted (\mex{1}c) and some can
undergo passivization (\mex{1}d).

\largerpage
\eal
\ex 
\gll dass er ihm den Garaus macht\\
	 that he him the \textsc{garaus} makes\\
\glt `that he finishes him off (kills him)'
\ex 
\gll Er macht ihm den Garaus.\\
	 he makes him the \textsc{garaus}\\
\glt `He finishes him off.'
\ex
In Amerika sagte man der Kamera nach, die größte Kleinbildkamera der Welt zu sein. Sie war laut
Schleiffer am Ende der Sargnagel der Mühlheimer Kameraproduktion.\\
\gll 
\emph{Den} \emph{Garaus} \emph{machte} ihr die Diskussion um die Standardisierung des 16-Millimeter-Filmformats,
an dessen Ende die DIN-Norm 19022 (Patrone mit Spule für 16-Millimeter-Film) stand, die im März 1963
zur Norm wurde.\footnotemark\\
the \textsc{garaus} made her
the discussion around the standardization of.the 16-millimeter-film.format at whose end the DIN-norm 19022
\spacebr{}cartridge with coil for 16-millimeter-film stood that in March 1963 to.the norm
became\\
\footnotetext{%
Frankfurter Rundschau, 28.06.1997, p.\,2. %, Ressort: LOKAL-RUNDSCHAU; Fotoapparatesammler Karl-Christian Schelzke regt Ausstellungen an
}
\glt `In America, one says that this camera was the biggest compact camera in the world. According to Schleiffer, it was the
last nail in the coffin for camera production in Mühlheim. What finished it off was the discussion about standardizing
the 16 millimeter format, which resulted in the DIN-Norm 19022 (cartridge with coil for 16 millimeter film) that became
the norm in March 1963.'
\ex
\gll in Heidelberg wird "`parasitären Elementen"' unter den Professoren \emph{der} \emph{Garaus} \emph{gemacht}\footnotemark\\
	 in Heidelberg are \hspaceThis{"`}parasitic elements among the professors the \textsc{garaus} made\\
\footnotetext{%
Mannheimer Morgen, 28.06.1999, Sport; Schrauben allein genügen nicht.%%M99/906.41526 Mannheimer
}
\glt `In Heidelberg, ``parasitic elements'' among professors are being killed off.'
\zl
\noindent
It is assumed that the periphery and lexicon are not components of UG (\citealp[\page 150--151]{Chomsky86a}; \citealp[\page 343]{Fodor98a})
but rather are acquired using other learning methods -- namely inductively directly from the input. The question posed by critics is now why these methods should not work for regular aspects of the language as well (\citealp[\page 20]{Abney96a}; 
% steht da nicht \citealp[\page 9]{Culicover99a-u};\note{check, zitiert nach Newmeyer2005} 
\citealp[\page 222]{Goldberg2003b}; \citealp[\page
100]{Newmeyer2005a}; Tomasello \citeyear[\page 36]{Tomasello2006a}; \citeyear[\page
20]{Tomasello2006c}): the areas of the so"=called `core' are by definition more regular then components of the periphery, which is why
they should be easier to learn.

\citet{Tomasello2000a,Tomasello2003a}\todostefan{\citet{Behrens2009a}} has pointed out that a Principles \& Parameters model of language acquisition
is not compatible with the observable facts. The \ppt predicts that children should no longer make mistakes in a particular area of grammar once they have set
a particular parameter correctly (see \citealp[\page 146]{Chomsky86a}, \citealp[\page 21--22]{Radford90a-u} and \citealp[\page
175]{Lightfoot97a}).
Furthermore, it is assumed that a parameter is responsible for very different areas of grammar (see the discussion of the pro"=drop parameter in
Section~\ref{Abschnitt-PP}). When a parameter value is set, then there should be sudden developments with regard to a number
of phenomena \citep[\page 174]{Lightfoot97a}. This is, however, not the case. Instead, children acquire language from utterances in their input
and begin to generalize from a certain age. Depending on the input, they can reorder certain auxiliaries and not others, although
movement of auxiliaries\is{auxiliary inversion} is obligatory in English\il{English}.\footnote{%
	Here, Yang's suggestion to combine grammars with a particular probability does not help since one
	would have to assume that the child uses different grammars for different auxiliaries, which
        is highly unlikely.
}
One argument put forward against these kinds of input"=based theories is that children produce utterances that cannot be observed
to a significant frequency in the input. One much discussed phenomenon of this kind are so called \emph{root infinitives}\is{root Infinitive} (RI) or \emph{optional
  infinitives}\is{optional infinitive} (OI) \citep{Wexler98a}.\il{English|(} These are infinitive forms that can be used in non"=embedded clauses (\emph{root sentences})
instead of a finite verb. Optional infinitives are those where children use both a finite (\mex{1}a) and non"=finite (\mex{1}b) form \citep[\page 59]{Wexler98a}:
\eal
\ex Mary likes ice cream.
\ex Mary like ice cream.
\zl
\citet*[\page 656]{WKG2001a} showed that Dutch\il{Dutch|(} children use the order object infinitive 90\,\% of the time during the two"=word phase although
these orders occur in less than 10\,\% of their mother's utterances that contained a verb.
Compound verb forms, \eg with a modal in initial position as in (\mex{1}) that contain another instance of this pattern only occurred in 30\,\% of the input containing
a verb \citep*[\page 647]{WKG2001a}.
\ea
\gll Willst du Brei essen?\\
     want   you porridge eat\\
\glt `Do you want to eat porridge?'
\z
\largerpage
At first glance, there seems to be a discrepancy between the input and the child's utterances.
However, this deviation could also be explained by an utterance"=final bias\is{bias} in learning (\citealp{WKG2001a}; \citealp*{FPG2006a}).
A number of factors can be made responsible for the salience of verbs at the end of an utterance:
1) restrictions of the infant brain. It has been shown that humans (both children and adults) forget words during the course of an
utterance, that is, the activation potential decreases. Since the cognitive capabilities of small children are restricted,
it is clear why elements at the end of an utterance have an important status. 2) Easier segmentation\is{segmentation} at
the end of an utterance. At the end of an utterance, part of the segmentation problem for hearers disappears:
the hearer first has to divide a sequence of phonemes into individual words before he can understand them and
combine them to create larger syntactic entities.
This segmentation is easier at the end of an utterance since the word boundary is already given by the end of the utterance.
Furthermore according to \citet*[\page 637]{WKG2001a}, utterance"=final words have an above average length and do bear a pitch
accent. This effect occurs more often in language directed at children.

\citet*{FPAG2007a} have modeled language acquisition for English\il{English}, German, Dutch\il{Dutch}, and Spanish\il{Spanish|(}.
The computer model could reproduce differences between these languages based on input. At first glance, it
is surprising that there are even differences between German and Dutch and between English and Spanish with regard to the use of infinitives as
German and Dutch have a very similar syntax (SOV+V2). Similarly, English and Spanish are both languages with SVO order.
Nevertheless, children learning English make OI mistakes, whereas this is hardly ever the case for children learning Spanish.

\citet*{FPAG2007a} trace the differences in error frequencies back to the distributional differences in each language:
the authors note that 75\,\% of verb"=final utterances\footnote{%
	For English, the authors only count utterances with a subject in third person singular since it is only in these cases
	that a morphological difference between the finite and infinitive form becomes clear.%
}
in English consist of compound verbs (finite verb $+$ dependent verb, \eg \emph{Can he go?}), whereas this is only the case
30\,\% of the time in Dutch.

German also differs from Dutch with regard to the number of utterance"=final infinitives. Dutch has a progressive form
that does not exist in Standard German:
\ea
\gll Wat ben je aan het doen?\\
     what are you on it do.\textsc{inf}\\
\glt `What are you doing?'
\z
Furthermore, verbs such as \emph{zitten} `to sit', \emph{lopen} `to run' and \emph{staan}
`to stand' can be used in conjunction with the infinitive to describe events happening in that moment:
\ea
\gll Zit je te spelen?\\
     sit you to play\\
\glt `Are you sitting and playing?' 
\z
Furthermore, there is a future form\is{future} in Dutch that is formed with \emph{ga} `go'. These factors
contribute to the fact that Dutch has 20\,\% more utterance"=final infinitives than German.

Spanish differs from English in that it has object clitics\is{clitic}:
\ea
\gll (Yo) Lo quiero.\\
     \hspaceThis{(}I it want\\
\glt `I want it.'
\z
Short pronouns such as \emph{lo} in (\mex{0}) are realized in front of the finite verb so that the verb
appears in final position. In English, the object follows the verb, however. Furthermore, there are
a greater number of compound verb forms in the English input (70\,\%) than in Spanish (25\,\%).
This is due to the higher frequency of the progressive\is{progressive} in English and the
presence of \emph{do}"=support\is{do"=Support@\emph{do}"=Support} in question formation.\il{Spanish|)}

The relevant differences in the distribution of infinitives are captured correctly by the proposed acquisition model,
whereas alternative approaches that assume that children possess an adult grammar but use infinitives
instead of the finite forms cannot explain the gradual nature of this phenomenon.

\citet*{FPG2009a} could even show that input"=based learning is superior to other explanations for the distribution of
NPs and infinitives. They can explain why this order is often used with a modal meaning (\eg \emph{to want})\is{verb!modal}
in German\il{German} and Dutch\il{Dutch} \citep{IT96a}. 
In these languages, infinitives occur with modal verbs in the corresponding interrogative clauses. Alternative approaches that
assume that the linguistic structures in question correspond to those of adults and only differ from them in that a modal verb
is not pronounced cannot explain why not all utterances of object and verb done by children learning German and Dutch do have a modal meaning.
Furthermore, the main difference to English cannot be accounted for: in English, the number of modal meanings is considerably
less. Input"=based models predict this exactly since English can use the dummy verb \emph{do} to form questions:
\eal
\ex Did he help you?
\ex Can he help you?
\zl
If larger entities are acquired from the end of an utterance, then there would be both a modal and non"=modal
context for \emph{he help you}. Since German and Dutch normally do not use the auxiliary \emph{tun} `do', 
the relevant endings of utterances are always associated with modals contexts.  One can thereby explain
why infinitival expressions have a modal meaning significantly more often in German and Dutch than in English.\il{English|)}\il{Dutch|)} 

Following this discussion of the arguments against input"=based theories of acquisition, I will turn to Tomasello's pattern"=based approach\indexcxgstart.
According to \citet[Section~4.2.1]{Tomasello2003a}, a child hears a sentence such as (\mex{1}) and realizes that particular slots can
be filled freely (see also \citew{Dabrowska2001a} for analogous suggestions in the framework of Cognitive Grammar\is{Cognitive Grammar}).
\eal
\ex Do you want more juice/milk?
\ex Mommy is gone.
\zl
From these utterances, it is possible to derive so"=called pivot schemata\is{pivot schema} such as those in (\mex{1}) into which words
can then be inserted:
\eal
\ex more \_\_\_ $\to$ more juice/milk
\ex \_\_\_ gone $\to$ mommy/juice gone
\zl
In this stage of development (22 months), children do not generalize using these schemata, these schemata are instead construction islands
and do not yet have any syntax \citep{TADR97a}. The ability to use previously unknown verbs with a subject and an object in an SVO order
is acquired slowly between the age of three and four \citep[\page 128--129]{Tomasello2003a}.
More abstract syntactic and semantic relations only emerge with time: when confronted with multiple instantiations of the transitive construction,
the child is then able to generalize:
\eal
\label{Beispiele-fuer-Transitivkonstruktion}
\ex {}[\sub{S} [\sub{NP} The man/the woman] sees  [\sub{NP} the dog/the rabbit/it]].
\ex {}[\sub{S} [\sub{NP} The man/the woman] likes [\sub{NP} the dog/the rabbit/it]].
\ex {}[\sub{S} [\sub{NP} The man/the woman] kicks [\sub{NP} the dog/the rabbit/it]].
\zl
According to \citet[\page 107]{Tomasello2003a}, this abstraction takes the form [Sbj TrVerb Obj]. 
Tomasello's approach is immediately plausible since one can recognize how abstraction works:
it is a generalization about reoccurring patterns. Each pattern is then assigned a semantic contribution.
These generalizations can be captured in inheritance hierarchies (see page~\pageref{Seite-Typhierarchie}) \citep[\page
  26]{Croft2001a}.
The problem with this kind of approach, however, is that it cannot explain the interaction between different areas of phenomena in the
language: it is possible to represent simple patterns such as the use of transitive verbs in
(\mex{0}), but transitive verbs interact with other areas of the grammar such as negation. If one wishes to connect the construction one assumes for the negation
of transitive verbs with the transitive construction, then one arrives at a problem since this is not possible in
inheritance hierarchies.
\ea
The woman did not kick the dog.
\z
\largerpage
The problem is that the transitive construction has a particular semantic contribution but that
negated transitive construction has the opposite meaning. The values of \textsc{sem} features would
therefore be contradictory. There are technical tricks to avoid this problem, however, since there
are a vast number of these kinds of interactions between syntax and semantics, this kind of
technical solution will result in something highly implausible from a cognitive perspective
\citep{Mueller2006d,Mueller2007d,MuellerLehrbuch1,MuellerPersian,MWArgSt}. 
For discussion of Croft's analysis, see Section~\ref{Abschnitt-Croft}.

At this point, proponents of pattern"=based analyses might try and argue that these kinds of problems are only
the result of a poor/inadequate formalization\is{formalization} and would rather do without a formalization
\citep[Section~5]{Goldberg2009a}. However, this does not help here as the problem is not the formalization itself, rather
the formalization allows one to see the problem more clearly.

\begin{sloppypar}
An alternative to an approach built entirely on inheritance is a TAG"=like approach that allows one to insert syntactic material
into phrasal constructions. Such a proposal was discussed in Section~\ref{sec-ECG}. \citet[\page
  170]{BC2005a} working in Embodied
Construction Grammar suggest an Active"=Ditransitive Construction with the form \mbox{[RefExpr Verb
RefExpr RefExpr]}, where RefExpr stands for a referential expression and the first RefExpr and the
verb may be non-adjacent. In this way, it is possible to analyze (\mex{1}a,b), while ruling out
(\mex{1}c):
\end{sloppypar}
\eal
\ex[]{
Mary tossed me a drink.
}
\ex[]{
Mary happily tossed me a drink.
}
\ex[*]{
Mary tossed happily me a drink.
}
\zl
While the compulsory adjacency of the verb and the object correctly predicts that (\mex{0}c) is
ruled out, the respective constraint also rules out coordinate structures\is{coordination} such as (\mex{1}):
\ea
Mary tossed me a juice and Peter a water.
\z
Part of the meaning of this sentence corresponds to what the ditransitive construction contributes to
\emph{Mary tossed Peter a water}. There is, however, a gap between \emph{tossed} and \emph{Peter}.
Similarly, one can create examples where there is a gap between both objects of a ditransitive construction:
\ea
He showed me and bought for Mary the book that was recommended in the Guardian last week.
\z
In (\mex{0}), \emph{me} is not adjacent to \emph{the book \ldots}. It is not my aim here to request a coordination
analysis. Coordination is a very complex phenomenon for which most theories do not have a straightforward analysis (see Section~\ref{Abschnitt-Koordination}).
Instead, I would simply like to point out that the fact that constructions can be realized discontinuously poses a problem for approaches that claim that language acquisition is exclusively
pattern"=based. The point is the following: in order to understand coordination data in a language, a speaker must learn that a verb which has its arguments somewhere in the sentence has
a particular meaning together with these arguments. The actual pattern [Sbj V Obj1 Obj2] can, however, be interrupted in all positions.
In addition to the coordination examples, there is also the possibility of moving elements out of the pattern either to the left or the right.
In sum, we can say that language learners have to learn that there is a relation between functors and their arguments. This is all that is left of
pattern"=based approaches but this insight is also covered by the selection"=based approaches that we will discuss in the following section.

\largerpage
A defender of pattern"=based approaches could perhaps object that there is a relevant construction for (\mex{0}) that combines
all material. This means that one would have a construction with the form [Sbj V Obj1 Conj V PP Obj2].
It would then have to be determined experimentally or with corpus studies whether this actually makes sense.
The generalization that linguists have found is that categories with the same syntactic properties can be coordinated 
(N, \nbar, NP, V, \vbar, VP, \ldots).\todostefan{Bei DG diskutieren} For the coordination of verbs or verbal projections, it must hold that the coordinated
phrases require the same arguments:
\eal
\ex 
\gll Er [arbeitet] und [liest viele Bücher].\\
     he \spacebr{}works and \spacebr{}reads many books\\
\ex 
\gll Er [kennt und liebt] diese Schallplatte.\\
     he \spacebr{}knows and loves this record\\
\ex 
\gll Er [zeigt dem Jungen] und [gibt der Frau] die Punk-Rock-CD.\\
     he \spacebr{}shows the boy and \spacebr{}gives the woman the {punk rock CD}\\
\ex 
\gll Er [liebt diese Schallplatte] und [schenkt ihr ein Buch].\\
     he \spacebr{}loves this record and \spacebr{}gives her a book\\
\zl
In an approach containing only patterns, one would have to assume an incredibly large number of constructions and so far we are
only considering coordinations that consist of exactly two conjuncts. However, the phenomenon discussed above is not only restricted
to coordination of two elements. If we do not wish to abandon the distinction between competence and performance\is{competence}\is{performance}
(see Chapter~\ref{Abschnitt-Diskussion-Performanz}), then the number of conjuncts is not constrained at all (by the competence grammar):
\ea
\gll Er [kennt, liebt und verborgt] diese Schallplatte.\\
	 he \spacebr{}knows loves and lends.out this record\\
\z
It is therefore extremely unlikely that learners have patterns for all possible cases in their input. It is much more likely that they draw
the same kind of generalizations as linguists from the data occurring in their input: words and phrases with the same syntactic
properties can be coordinated. 
If this turns out to be true, then all that is left for pattern"=based approaches is the assumption of discontinuously realized constructions
and thus a dependency between parts of constructions that states that they do not have to be immediately adjacent to one another.
The acquisition problem is then the same as for selection"=based approaches that will be the topic of the following section: what ultimately has
to be learned are dependencies between elements or valences (see \citew[\page 439]{Behrens2009a}, the author reaches the same conclusion
following different considerations).%
\indexcxgend

\section{Selection"=based approaches}
\label{Abschnitt-Selektionsbasierter-Spracherwerb}

I will call the alternative to pattern"=based approaches \emph{selection"=based}. A selection"=based approach has
been proposed by \citet{Green-Grammar-Growth}.  

The generalizations about the pattern in (\ref{Beispiele-fuer-Transitivkonstruktion}) pertain to the valence class of the verb.
In Categorial Grammar, the pattern [Sbj TrVerb Obj] corresponds to the lexical entry (s\bs np)/np (for the derivation of a sentence
with this kind of lexical entry, see Figure~\ref{abb-the-cat-chased-Mary} on page~\pageref{abb-the-cat-chased-Mary}).
A TAG tree for \emph{likes} was given on page~\pageref{Abbildung-Max-likes-Anouk}.
Here, one can see quite clearly that lexical entries determine the structure of sentences in these models. Unlike pattern"=based approaches, these analyses allow
enough room for semantic embedding: the lexical entries in Categorial Grammar can be combined with adjuncts, and elementary trees in TAG also allow for adjunction
to the relevant nodes.

Now, we face the question of how the jump from a pivot schema to a lexical entry with an argument structure takes place. In Tomasello's approach, there is no break between them. Pivot schemata
are phrasal patterns and [Sbj TrVerb Obj] is also a phrasal pattern. Both schemata have open slots into which certain elements can be inserted.
In selection"=based approaches, the situation is similar: the elements that are fixed in the pivot schema are functors\is{functor} in the selection"=based approach.
\citet{Green-Grammar-Growth} proposes a theory of acquisition in HPSG that can do without UG. For the two"=word phase, she assumes that  \emph{where's} is the head
of an utterance such as (\mex{1}) and that \emph{where's} selects \emph{Robin} as its argument.
\ea
Where's Robin?
\z
This means that, rather than assuming that there is a phrasal pattern \emph{Where's} X? with an empty slot X for a person
or thing, she assumes that there is a lexical entry \emph{where's}, which contains the information that it  needs to be combined
with another constituent. What needs to be acquired is the same in each case: there is particular material that has to be combined
with other material in order to yield a complete utterance.

In her article, Green shows how long"=distance dependencies and the position of English auxiliaries can be acquired in later stages of development.
The acquisition of grammar proceeds in a monotone fashion, that is, knowledge is added -- for example, knowledge about the fact that
material can be realized outside of the local context -- and previous knowledge does not have to be revised.
In her model, mistakes in the acquisition process are in fact mistakes in the assignment of lexical
entries to valence classes. These mistakes have to be correctable. 

In sum, one can say that all of Tomasello's insights can be applied directly to selection"=based approaches and the problems with pattern"=based
approaches do not surface with selection"=based approaches. It is important to point out explicitly once again here that the selection"=based approach
discussed here also is a construction"=based approach. Constructions are just lexical and not phrasal.
The important point is that, in both approaches, words and also more complex phrases are pairs of form and meaning and can be acquired as such.

In Chapter~\ref{Abschnitt-Phrasal-Lexikalisch}, we will discuss pattern"=based approaches further
and we will also explore areas of the grammar where phrasal patterns should be assumed.

\section{Summary}

We should take from the preceding discussion that models of language acquisition that assume that a grammar is chosen
from a large set of grammars by setting binary parameters are in fact inadequate.
All theories that make reference to parameters have in common that they are purely hypothetical since there is no
non"=trivial set of parameters that all proponents of the model equally agree on. In fact there is
not even a trivial one.

In a number of experiments, Tomasello and his colleagues have shown that, in its original form, the Principles \& Parameters model makes incorrect
predictions and that language acquisition is much more pattern"=based than assumed by proponents of P\&P analyses.
Syntactic competence develops starting from verb islands. Depending on the frequency of the input, certain verbal constructions can be
mastered even though the same construction has not yet been acquired with less frequent verbs.

The interaction with other areas of grammar still remains problematic for pattern"=based approaches: in a number of publications, it has been shown
that the interaction of phenomena that one can observe in complex utterances can in fact not be explained with phrasal patterns since
embedding cannot be captured in an inheritance hierarchy. This problem is not shared by selection"=based approaches. All experimental results and insights
of Tomasello can, however, be successfully extended to selection"=based approaches.%
\is{acquisition|)}

\pagebreak
~\newline\vspace*{-10mm}
\furtherreading{

\citet{Meisel95a} gives a very good overview of theories of acquisition in the Principles \& Parameters model.

Adele Goldberg and Michael Tomasello are the most prominent proponents of Construction Grammar, a theory that explicitly tries
to do without the assumption of innate linguistic knowledge. They published many papers and books
about topics related to Construction Grammar and acquisition. The most important books probably are \citew{Goldberg2006a} and \citew{Tomasello2003a}.

An overview of different theories of acquisition in German can be found in \citet{KD2008a} an
English overview is \citew{AL2011a-u}.
}


%      <!-- Local IspellDict: en_US-w_accents -->
